{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "POS_NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTAEuTboNeJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the required libraries.\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import collections\n",
        "import operator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "\n",
        "random.seed(11)\n",
        "np.random.seed(11)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq2bZOCyNeKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Conv1D, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation, Masking, Flatten\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF8Th5RcOAka",
        "colab_type": "code",
        "outputId": "50a4601e-cd84-40b5-a159-3bba41157b1f",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cc4bfb9b-115d-4bbf-9aa4-583a0f7df9d0\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-cc4bfb9b-115d-4bbf-9aa4-583a0f7df9d0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Brown_train.txt to Brown_train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkPYCVj_NeKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_sentence(sentence):\n",
        "    '''\n",
        "    Function for parsing the words and tags from the\n",
        "    sentences of the input corpus.\n",
        "    '''\n",
        "    word_tag_pairs = sentence.split(\" \")\n",
        "    words = []\n",
        "    tags = []\n",
        "\n",
        "    for i, word_tag in enumerate(word_tag_pairs):\n",
        "        word, tag = word_tag.strip().rsplit('/', 1)\n",
        "        words.append(word)\n",
        "        tags.append(tag)\n",
        "        \n",
        "    return words, tags"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXUd2ekoNeKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parse the sentences into a list.\n",
        "parsed_sentences = []\n",
        "\n",
        "with open('./Brown_train.txt', 'r') as file:\n",
        "    sentences = file.readlines()\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()\n",
        "        parsed_sentences.append(parse_sentence(sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwyuAfjGNeKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_vocab(X_train, Y_train):\n",
        "    '''\n",
        "    Function for building the vocabulary from the training set of\n",
        "    words and tags.\n",
        "    '''\n",
        "    vocabulary2id = dict()    \n",
        "    tag2id = dict()\n",
        "    vocabulary2id['PAD'] = 0\n",
        "    vocabulary2id['UNK'] = 1\n",
        "\n",
        "    for sent in X_train:\n",
        "        for word in sent:\n",
        "            if word not in vocabulary2id.keys():\n",
        "                vocabulary2id[word] = len(vocabulary2id)\n",
        "    \n",
        "    tag2id['PAD'] = 0\n",
        "    for sent in Y_train:\n",
        "        for tag in sent:\n",
        "            if tag not in tag2id.keys():\n",
        "                tag2id[tag] = len(tag2id)\n",
        "    \n",
        "    return vocabulary2id, tag2id\n",
        "\n",
        "def get_word_tag_counts(X_train, Y_train, vocabulary2id, tag2id):\n",
        "    '''\n",
        "    Function for calculating the counts pertaining to the\n",
        "    individual word tags.\n",
        "    '''\n",
        "    wordcount = defaultdict(int)\n",
        "    tagcount = defaultdict(int)\n",
        "    tagpaircount = defaultdict(int)\n",
        "    tagtriplecount = defaultdict(int)\n",
        "    \n",
        "    for sent in X_train:\n",
        "        for word in sent:\n",
        "            wordcount[word] += 1\n",
        "    \n",
        "    for sent in Y_train:\n",
        "        for tag in sent:\n",
        "            tagcount[tag] += 1\n",
        "    \n",
        "    for sent in Y_train:\n",
        "        for i in range(len(sent) - 1):\n",
        "            tagpaircount[sent[i], sent[i + 1]] += 1\n",
        "\n",
        "    for sent in Y_train:\n",
        "        for i in range(len(sent) - 2):\n",
        "            tagtriplecount[sent[i], sent[i + 1], sent[i + 2]] += 1\n",
        "    \n",
        "    return wordcount, tagcount, tagpaircount, tagtriplecount"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtYOouggNeK0",
        "colab_type": "code",
        "outputId": "5be42b92-eea2-4b3c-8509-0c7a832cdb24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "parsed_sentences[:5]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['At',\n",
              "   'that',\n",
              "   'time',\n",
              "   'highway',\n",
              "   'engineers',\n",
              "   'traveled',\n",
              "   'rough',\n",
              "   'and',\n",
              "   'dirty',\n",
              "   'roads',\n",
              "   'to',\n",
              "   'accomplish',\n",
              "   'their',\n",
              "   'duties',\n",
              "   '.'],\n",
              "  ['ADP',\n",
              "   'DET',\n",
              "   'NOUN',\n",
              "   'NOUN',\n",
              "   'NOUN',\n",
              "   'VERB',\n",
              "   'ADJ',\n",
              "   'CONJ',\n",
              "   'ADJ',\n",
              "   'NOUN',\n",
              "   'PRT',\n",
              "   'VERB',\n",
              "   'DET',\n",
              "   'NOUN',\n",
              "   '.']),\n",
              " (['Using',\n",
              "   'privately-owned',\n",
              "   'vehicles',\n",
              "   'was',\n",
              "   'a',\n",
              "   'personal',\n",
              "   'hardship',\n",
              "   'for',\n",
              "   'such',\n",
              "   'employees',\n",
              "   ',',\n",
              "   'and',\n",
              "   'the',\n",
              "   'matter',\n",
              "   'of',\n",
              "   'providing',\n",
              "   'state',\n",
              "   'transportation',\n",
              "   'was',\n",
              "   'felt',\n",
              "   'perfectly',\n",
              "   'justifiable',\n",
              "   '.'],\n",
              "  ['VERB',\n",
              "   'ADJ',\n",
              "   'NOUN',\n",
              "   'VERB',\n",
              "   'DET',\n",
              "   'ADJ',\n",
              "   'NOUN',\n",
              "   'ADP',\n",
              "   'ADJ',\n",
              "   'NOUN',\n",
              "   '.',\n",
              "   'CONJ',\n",
              "   'DET',\n",
              "   'NOUN',\n",
              "   'ADP',\n",
              "   'VERB',\n",
              "   'NOUN',\n",
              "   'NOUN',\n",
              "   'VERB',\n",
              "   'VERB',\n",
              "   'ADV',\n",
              "   'ADJ',\n",
              "   '.']),\n",
              " (['Once',\n",
              "   'the',\n",
              "   'principle',\n",
              "   'was',\n",
              "   'established',\n",
              "   ',',\n",
              "   'the',\n",
              "   'increase',\n",
              "   'in',\n",
              "   'state-owned',\n",
              "   'vehicles',\n",
              "   'came',\n",
              "   'rapidly',\n",
              "   '.'],\n",
              "  ['ADP',\n",
              "   'DET',\n",
              "   'NOUN',\n",
              "   'VERB',\n",
              "   'VERB',\n",
              "   '.',\n",
              "   'DET',\n",
              "   'NOUN',\n",
              "   'ADP',\n",
              "   'ADJ',\n",
              "   'NOUN',\n",
              "   'VERB',\n",
              "   'ADV',\n",
              "   '.']),\n",
              " (['And',\n",
              "   'reasons',\n",
              "   'other',\n",
              "   'than',\n",
              "   'employee',\n",
              "   'need',\n",
              "   'contributed',\n",
              "   'to',\n",
              "   'the',\n",
              "   'growth',\n",
              "   '.'],\n",
              "  ['CONJ',\n",
              "   'NOUN',\n",
              "   'ADJ',\n",
              "   'ADP',\n",
              "   'NOUN',\n",
              "   'NOUN',\n",
              "   'VERB',\n",
              "   'ADP',\n",
              "   'DET',\n",
              "   'NOUN',\n",
              "   '.']),\n",
              " (['Table',\n",
              "   '1',\n",
              "   'immediately',\n",
              "   'below',\n",
              "   'shows',\n",
              "   'the',\n",
              "   'rate',\n",
              "   'of',\n",
              "   'growth',\n",
              "   'of',\n",
              "   'vehicles',\n",
              "   'and',\n",
              "   'employees',\n",
              "   '.'],\n",
              "  ['NOUN',\n",
              "   'NUM',\n",
              "   'ADV',\n",
              "   'ADV',\n",
              "   'VERB',\n",
              "   'DET',\n",
              "   'NOUN',\n",
              "   'ADP',\n",
              "   'NOUN',\n",
              "   'ADP',\n",
              "   'NOUN',\n",
              "   'CONJ',\n",
              "   'NOUN',\n",
              "   '.'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7JLr5AedooV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape=(5, )))\n",
        "    # model.add(Masking(mask_value=float(vocabulary2id['UNK']),input_shape=(5,)))\n",
        "    model.add(Embedding(len(vocabulary2id), 100))\n",
        "    model.add(Flatten())\n",
        "    # model.add(Bidirectional(LSTM(int((128+256)/2), return_sequences=True)))\n",
        "    # model.add(TimeDistributed(Dense(len(tag2id))))\n",
        "    model.add(Dense(len(tag2id)))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=Adam(0.001),\n",
        "                  metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeP15prFd7m_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def id2onehot(Y, numtags):\n",
        "    out = []\n",
        "    for s in Y:\n",
        "        out.append(np.zeros(numtags))\n",
        "        out[-1][s] = 1.0\n",
        "    return np.array(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUmQkpytzuJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_example(words, vocabulary2id):\n",
        "    words_new = ['PAD', 'PAD'] + words + ['PAD', 'PAD']\n",
        "    examples = []\n",
        "    for i in range(len(words)):\n",
        "        context_words = words_new[i: i + 5]\n",
        "        context_word_idx = [vocabulary2id[w] if w in vocabulary2id.keys() else vocabulary2id['UNK'] for w in context_words]\n",
        "        examples.append(context_word_idx)\n",
        "\n",
        "    return examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMo1HI3CNeK_",
        "colab_type": "code",
        "outputId": "78c7dcfc-5973-40b7-8394-b4469cdc4ca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Build the test and training sets of sentences.\n",
        "kf = KFold(n_splits = 3, shuffle = False)\n",
        "parsed_sentences = np.asarray(parsed_sentences)\n",
        "scores = []\n",
        "scores1 = []\n",
        "y_pred_idx = []\n",
        "y_pred_idx1 = []\n",
        "y_test_idx = []\n",
        "y_test_idx1 = []\n",
        "\n",
        "preds_all_folds = []\n",
        "golds_all_folds = []\n",
        "\n",
        "for fold_num, (train_index, test_index) in enumerate(kf.split(parsed_sentences)):\n",
        "    train_data = parsed_sentences[train_index]\n",
        "    test_data = parsed_sentences[test_index]\n",
        "    X_train = [a[0] for a in train_data]\n",
        "    Y_train = [a[1] for a in train_data]\n",
        "    X_test = [a[0] for a in test_data]\n",
        "    Y_test = [a[1] for a in test_data]\n",
        "\n",
        "    # Build the vocabulary and word counts.\n",
        "    vocabulary2id, tag2id = get_vocab(X_train, Y_train)\n",
        "\n",
        "    # padlen = max(len(i) for i in X_train)\n",
        "    # def pad(sentence, padid=vocabulary2id['PAD']):\n",
        "    #     out = sentence[:padlen]\n",
        "    #     padding = [padid for _ in range(padlen - len(out))]\n",
        "    #     return out + padding\n",
        "    # break\n",
        "    X_train_ids = []\n",
        "    Y_train_ids = []\n",
        "    for x_sent, y_sent in zip(X_train, Y_train):\n",
        "        X_train_ids.extend(make_example(x_sent, vocabulary2id))\n",
        "        Y_train_ids.extend([tag2id[word] if word in tag2id.keys() else tag2id['UNK'] for word in y_sent])\n",
        "\n",
        "    X_test_ids = []\n",
        "    Y_test_ids = []\n",
        "    for x_sent, y_sent in zip(X_test, Y_test):\n",
        "        X_test_ids.extend(make_example(x_sent, vocabulary2id))\n",
        "        Y_test_ids.extend([tag2id[word] if word in tag2id.keys() else tag2id['UNK'] for word in y_sent])\n",
        "    \n",
        "    X_train_ids = np.asarray(X_train_ids)\n",
        "    X_test_ids = np.asarray(X_test_ids)\n",
        "\n",
        "    # X_test_ids = np.array([pad([vocabulary2id[word] if word in vocabulary2id.keys() else vocabulary2id['UNK'] for word in sent]) for sent in X_test])\n",
        "\n",
        "    # Y_train_ids = np.asarray([pad([tag2id[word] if word in tag2id.keys() else tag2id['UNK'] for word in sent], tag2id['PAD']) for sent in Y_train])\n",
        "    # Y_test_ids = np.asarray([pad([tag2id[word] if word in tag2id.keys() else tag2id['UNK'] for word in sent], tag2id['PAD']) for sent in Y_test])\n",
        "\n",
        "    Y_train_onehot = id2onehot(Y_train_ids, len(tag2id))\n",
        "    Y_test_onehot = id2onehot(Y_test_ids, len(tag2id))\n",
        "\n",
        "    model = build_model()\n",
        "    model.fit(X_train_ids, Y_train_onehot, batch_size=128, epochs=5, validation_split=0.2)\n",
        "\n",
        "    predictions = model.predict(X_test_ids)\n",
        "\n",
        "    # test_accuracy = np.sum((Y_test_ids == np.argmax(predictions, axis=-1)) * (Y_test_ids != 0)) / np.sum((Y_test_ids != 0))\n",
        "    # print('Fold {} test_accuracy: {}'.format(fold_num + 1, test_accuracy))\n",
        "\n",
        "    predictions_argmax = np.argmax(predictions, axis=-1)\n",
        "\n",
        "    y_pred_nopad = predictions_argmax[:]\n",
        "    y_true_nopad = Y_test_ids[:]\n",
        "\n",
        "    # for i in range(len(Y_test_ids)):\n",
        "    #     if Y_test_ids[i] != 0 and predictions_argmax[i] != 0:\n",
        "    #         y_true_nopad.append(Y_test_ids[i][j])\n",
        "    #         if predictions_argmax[i][j] == 0:\n",
        "    #             y_pred_nopad.append(1)\n",
        "    #         else:\n",
        "    #             y_pred_nopad.append(predictions_argmax[i][j])\n",
        "\n",
        "    preds_all_folds.extend(y_pred_nopad)\n",
        "    golds_all_folds.extend(y_true_nopad)\n",
        "\n",
        "    y_pred_nopad = np.asarray(y_pred_nopad)\n",
        "    y_true_nopad = np.asarray(y_true_nopad)\n",
        "    test_accuracy = (y_pred_nopad == y_true_nopad).mean()\n",
        "    print('Fold {} test_accuracy: {}'.format(fold_num + 1, test_accuracy))\n",
        "    prec, rec, fscore, _ = precision_recall_fscore_support(y_true_nopad, y_pred_nopad, average = 'weighted')\n",
        "    print('Fold {} Precision: {} Recall: {} F1-Score: {}'.format(fold_num + 1, prec, rec, fscore))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 5, 100)            2211500   \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 13)                6513      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 13)                0         \n",
            "=================================================================\n",
            "Total params: 2,218,013\n",
            "Trainable params: 2,218,013\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 238759 samples, validate on 59690 samples\n",
            "Epoch 1/5\n",
            "238759/238759 [==============================] - 10s 41us/step - loss: 0.3795 - accuracy: 0.9070 - val_loss: 0.1536 - val_accuracy: 0.9527\n",
            "Epoch 2/5\n",
            "238759/238759 [==============================] - 8s 34us/step - loss: 0.0621 - accuracy: 0.9819 - val_loss: 0.1352 - val_accuracy: 0.9569\n",
            "Epoch 3/5\n",
            "238759/238759 [==============================] - 8s 34us/step - loss: 0.0337 - accuracy: 0.9895 - val_loss: 0.1373 - val_accuracy: 0.9557\n",
            "Epoch 4/5\n",
            "238759/238759 [==============================] - 8s 34us/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.1449 - val_accuracy: 0.9543\n",
            "Epoch 5/5\n",
            "238759/238759 [==============================] - 8s 34us/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.1567 - val_accuracy: 0.9521\n",
            "Fold 1 test_accuracy: 0.9145525132815693\n",
            "Fold 1 Precision: 0.9154295258590754 Recall: 0.9145525132815693 F1-Score: 0.9129063570699006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 5, 100)            2850100   \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 13)                6513      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 13)                0         \n",
            "=================================================================\n",
            "Total params: 2,856,613\n",
            "Trainable params: 2,856,613\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 318057 samples, validate on 79515 samples\n",
            "Epoch 1/5\n",
            "318057/318057 [==============================] - 12s 39us/step - loss: 0.3303 - accuracy: 0.9154 - val_loss: 0.1529 - val_accuracy: 0.9517\n",
            "Epoch 2/5\n",
            "318057/318057 [==============================] - 12s 37us/step - loss: 0.0511 - accuracy: 0.9847 - val_loss: 0.1410 - val_accuracy: 0.9541\n",
            "Epoch 3/5\n",
            "318057/318057 [==============================] - 12s 37us/step - loss: 0.0267 - accuracy: 0.9917 - val_loss: 0.1436 - val_accuracy: 0.9541\n",
            "Epoch 4/5\n",
            "318057/318057 [==============================] - 12s 37us/step - loss: 0.0164 - accuracy: 0.9950 - val_loss: 0.1532 - val_accuracy: 0.9532\n",
            "Epoch 5/5\n",
            "318057/318057 [==============================] - 12s 36us/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.1644 - val_accuracy: 0.9518\n",
            "Fold 2 test_accuracy: 0.9538182542571972\n",
            "Fold 2 Precision: 0.9539599018345375 Recall: 0.9538182542571972 F1-Score: 0.9538492424867576\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 5, 100)            2745900   \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 13)                6513      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 13)                0         \n",
            "=================================================================\n",
            "Total params: 2,752,413\n",
            "Trainable params: 2,752,413\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 312221 samples, validate on 78056 samples\n",
            "Epoch 1/5\n",
            "312221/312221 [==============================] - 11s 36us/step - loss: 0.3295 - accuracy: 0.9168 - val_loss: 0.1556 - val_accuracy: 0.9513\n",
            "Epoch 2/5\n",
            "312221/312221 [==============================] - 11s 36us/step - loss: 0.0499 - accuracy: 0.9852 - val_loss: 0.1445 - val_accuracy: 0.9534\n",
            "Epoch 3/5\n",
            "312221/312221 [==============================] - 11s 36us/step - loss: 0.0257 - accuracy: 0.9920 - val_loss: 0.1495 - val_accuracy: 0.9527\n",
            "Epoch 4/5\n",
            "312221/312221 [==============================] - 11s 36us/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.1559 - val_accuracy: 0.9523\n",
            "Epoch 5/5\n",
            "312221/312221 [==============================] - 11s 36us/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.1667 - val_accuracy: 0.9509\n",
            "Fold 3 test_accuracy: 0.9489507561881836\n",
            "Fold 3 Precision: 0.9486036941889606 Recall: 0.9489507561881836 F1-Score: 0.9486450303991145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiE8MC8BNeLG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "74b8a7b9-9ef8-445d-b016-7931b3e57b81"
      },
      "source": [
        "print(\"---Averaged Results over all the epochs---\")\n",
        "test_accuracy = (np.asarray(preds_all_folds) == np.asarray(golds_all_folds)).mean()\n",
        "print('Average K-Fold Test Accuracy: {}'.format(test_accuracy))\n",
        "prec, rec, fscore, _ = precision_recall_fscore_support(preds_all_folds, golds_all_folds, average = 'weighted')\n",
        "print('Average K-Fold Precision: {} Recall: {} F1-Score: {}'.format(prec, rec, fscore))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---Averaged Results over all the epochs---\n",
            "Average K-Fold Test Accuracy: 0.9347582339284433\n",
            "Average K-Fold Precision: 0.9363865544203436 Recall: 0.9347582339284433 F1-Score: 0.9351816000908588\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0Tr0kJzNeLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "dfff48b4-d514-4c12-8512-2ef00e607ae2"
      },
      "source": [
        "id2tag = {v: k for k, v in tag2id.items()}\n",
        "print(classification_report([id2tag[i] for i in golds_all_folds], [id2tag[i] for i in preds_all_folds]))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           .       0.99      1.00      0.99     74854\n",
            "         ADJ       0.87      0.89      0.88     51942\n",
            "         ADP       0.96      0.97      0.96     38784\n",
            "         ADV       0.89      0.79      0.84     37582\n",
            "        CONJ       0.88      0.93      0.91     73425\n",
            "         DET       0.95      0.94      0.95     44196\n",
            "        NOUN       0.95      0.95      0.95     83364\n",
            "         NUM       0.97      0.95      0.96      6795\n",
            "         PAD       0.00      0.00      0.00         0\n",
            "        PRON       0.98      0.92      0.95     27098\n",
            "         PRT       0.95      0.93      0.94     46106\n",
            "        VERB       0.94      0.95      0.95     58413\n",
            "           X       0.46      0.22      0.30       590\n",
            "\n",
            "    accuracy                           0.93    543149\n",
            "   macro avg       0.83      0.80      0.81    543149\n",
            "weighted avg       0.93      0.93      0.93    543149\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0QoOoQQNeLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}