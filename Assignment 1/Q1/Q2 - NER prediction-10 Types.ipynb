{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "import operator\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import Model, Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import *\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import math\n",
    "\n",
    "random.seed(11)\n",
    "np.random.seed(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER-Dataset-10Types-Train.txt\r\n",
      "NER-Dataset--TestSet.txt\r\n",
      "NER-Dataset-Train.txt\r\n",
      "Q1 - NER Prediction 10 Types (buggy).ipynb\r\n",
      "Q1 - NER prediction-10 Types (no test output)-Copy1.ipynb\r\n",
      "Q1 - NER prediction-10 Types (no test output).ipynb\r\n",
      "Q1 - NER prediction-10 Types (with test output).ipynb\r\n",
      "Q1 - NER prediction.ipynb\r\n",
      "Q1 - NER prediction (with test output).ipynb\r\n",
      "Q2.ipynb\r\n",
      "Q2 - NER prediction-10 Types.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('NER-Dataset-10Types-Train.txt', 'r') as f:\n",
    "    ner_dataset = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "words = []\n",
    "tags = []\n",
    "for line in ner_dataset:\n",
    "    line = line.strip()\n",
    "    if line == '':\n",
    "        sentences.append((words, tags))\n",
    "        words = []\n",
    "        tags = []\n",
    "    else:\n",
    "        word, tag = line.split('\\t')\n",
    "        words.append(word)\n",
    "        tags.append(tag)\n",
    "\n",
    "if len(words) > 0:\n",
    "    sentences.append((words, tags))\n",
    "    words = []\n",
    "    tags= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_counts = Counter(sum([a[0] for a in sentences], [])).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1456"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_keep = set([word for word, count in vocab_counts if count > 1])\n",
    "len(words_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsed_sentences = [([w if w in words_to_keep else 'UNK' for w in words], tags) for words, tags in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('NER-Dataset--TestSet.txt', 'r') as f:\n",
    "    test_dataset = f.readlines()\n",
    "\n",
    "test_sentences = []\n",
    "words = []\n",
    "for line in test_dataset:\n",
    "    line = line.strip()\n",
    "    if line == '':\n",
    "        test_sentences.append((words,))\n",
    "        words = []\n",
    "    else:\n",
    "        word = line\n",
    "        words.append(word)\n",
    "\n",
    "if len(words) > 0:\n",
    "    test_sentences.append((words,))\n",
    "    words = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = ['twoDigitNum',\n",
    "                'fourDigitNum',\n",
    "                'containsDigitAndAlpha',\n",
    "                'containsDigitAndDash',\n",
    "                'containsDigitAndSlash',\n",
    "                'containsDigitAndComma',\n",
    "                'containsDigitAndPeriod',\n",
    "                'otherNum',\n",
    "                'allCaps',\n",
    "                'capPeriod',\n",
    "                'firstWord',\n",
    "                'initCap',\n",
    "                'lowerCase',\n",
    "                'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_features(sentence):\n",
    "    features = []\n",
    "    ## Optimize and use an Enum!\n",
    "    firstword = True\n",
    "    for word in sentence:\n",
    "        if word.isnumeric() and len(word) == 2:\n",
    "            features.append('twoDigitNum')\n",
    "        elif word.isnumeric() and len(word) == 4:\n",
    "            features.append('fourDigitNum')\n",
    "        elif word.isalnum() and not word.isalpha() and not word.isnumeric():\n",
    "            features.append('containsDigitAndAlpha')\n",
    "        elif word.replace('-', '').isnumeric():\n",
    "            features.append('containsDigitAndAlpha')\n",
    "        elif word.replace('/', '').isnumeric():\n",
    "            features.append('containsDigitAndSlash')\n",
    "        elif word.replace('.', '').replace(',', '').isnumeric() and ',' in word:\n",
    "            features.append('containsDigitAndComma')\n",
    "        elif word.replace('.', '').isnumeric():\n",
    "            features.append('containsDigitAndPeriod')\n",
    "        elif word.isnumeric():\n",
    "            features.append('otherNum')\n",
    "        elif word.isupper():\n",
    "            features.append('allCaps')\n",
    "        elif len(word) == 2 and word[0].isupper() and word[1] == '.':\n",
    "            features.append('capPeriod')\n",
    "        elif firstword:\n",
    "            features.append('firstWord')\n",
    "        elif word[0].isupper():\n",
    "            features.append('initCap')\n",
    "        elif word.islower():\n",
    "            features.append('lowerCase')\n",
    "        else:\n",
    "            features.append('other')\n",
    "        firstword = False\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_found = max(len(s[0]) for s in sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max_len_found + ((50 - (max_len_found % 50)) % 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_mat = list(np.eye(len(word_features)))\n",
    "wordfeat2float = {feat: eye_mat[i] for i, feat in enumerate(word_features)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word2idx = {'UNK': 0, 'PAD': 1}\n",
    "word2idx.update({word: i + 2 for i, word in enumerate(sorted(words_to_keep))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberize_sentence(words, max_len=50):\n",
    "    features = get_word_features(words)\n",
    "    word_idx = [word2idx[w] if w in word2idx.keys() else word2idx['UNK'] for w in words]\n",
    "    feat_np = [wordfeat2float[f] for f in features]\n",
    "    word_padding = [word2idx['PAD'] for _ in range(max_len - len(word_idx))]\n",
    "    feat_padding = [np.ones((len(word_features),)) * 2 for _ in range(max_len - len(word_idx))]\n",
    "    word_idx = np.asarray(word_idx + word_padding)\n",
    "    feat_np = np.asarray(feat_np + feat_padding)\n",
    "    return word_idx, feat_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = set.union(*(set(s[1]) for s in sentences))\n",
    "n_labels = len(labels)\n",
    "eye_mat = list(np.eye(len(labels)))\n",
    "labels2float = {feat: eye_mat[i] for i, feat in enumerate(labels)}\n",
    "\n",
    "def numberize_labels(gt_labels, max_len=50):\n",
    "    labels_np = [labels2float[l] for l in gt_labels]\n",
    "    labels_padding = [labels2float['O'] for _ in range(max_len - len(gt_labels))]\n",
    "    return np.asarray(labels_np + labels_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_words = Input(shape=(max_len,))\n",
    "    input_feats = Input(shape=(max_len, len(word_features)))\n",
    "    masked_words = Masking(mask_value = 1)(input_words)\n",
    "    masked_feats = Masking(mask_value = 2)(input_feats)\n",
    "    emb = Embedding(input_dim=(len(word2idx)), output_dim=50, input_length=max_len)(masked_words)\n",
    "    drop_emb = Dropout(0.1)(emb)\n",
    "    concat_out = Concatenate()([drop_emb, masked_feats])\n",
    "    rnn_out = Bidirectional(SimpleRNN(units=100, return_sequences=True, recurrent_dropout=0.1))(concat_out)\n",
    "    dense_out = TimeDistributed(Dense(n_labels, activation=\"softmax\"))(rnn_out)\n",
    "    model = Model(inputs=[input_words, input_feats], outputs=dense_out)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_sentences = [(numberize_sentence(s[0]), numberize_labels(s[1])) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_test_sentences = [numberize_sentence(s[0]) for s in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'O': 16508,\n",
       "         'B-musicartist': 22,\n",
       "         'I-musicartist': 21,\n",
       "         'B-company': 71,\n",
       "         'B-geo-loc': 114,\n",
       "         'B-product': 32,\n",
       "         'B-person': 176,\n",
       "         'B-tvshow': 11,\n",
       "         'I-tvshow': 8,\n",
       "         'B-other': 89,\n",
       "         'I-other': 132,\n",
       "         'B-facility': 41,\n",
       "         'I-facility': 38,\n",
       "         'I-person': 91,\n",
       "         'B-movie': 12,\n",
       "         'I-movie': 17,\n",
       "         'I-geo-loc': 26,\n",
       "         'B-sportsteam': 14,\n",
       "         'I-product': 33,\n",
       "         'I-sportsteam': 5,\n",
       "         'I-company': 19})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(sum([s[1] for s in sentences], []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({15: 44028,\n",
       "         14: 22,\n",
       "         19: 21,\n",
       "         3: 71,\n",
       "         13: 114,\n",
       "         1: 32,\n",
       "         7: 176,\n",
       "         16: 11,\n",
       "         5: 8,\n",
       "         11: 89,\n",
       "         17: 132,\n",
       "         20: 41,\n",
       "         2: 38,\n",
       "         9: 91,\n",
       "         12: 12,\n",
       "         18: 17,\n",
       "         4: 26,\n",
       "         6: 14,\n",
       "         10: 33,\n",
       "         8: 5,\n",
       "         0: 19})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(sum([np.argmax(s[1], axis=-1).tolist() for s in parsed_sentences], []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights = compute_class_weight('balanced', np.unique(sum([np.argmax(s[1], axis=-1).tolist() for s in parsed_sentences], [])), sum([np.argmax(s[1], axis=-1).tolist() for s in parsed_sentences], []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.12781955e+02, 6.69642857e+01, 5.63909774e+01, 3.01810865e+01,\n",
       "       8.24175824e+01, 2.67857143e+02, 1.53061224e+02, 1.21753247e+01,\n",
       "       4.28571429e+02, 2.35478807e+01, 6.49350649e+01, 2.40770465e+01,\n",
       "       1.78571429e+02, 1.87969925e+01, 9.74025974e+01, 4.86703267e-02,\n",
       "       1.94805195e+02, 1.62337662e+01, 1.26050420e+02, 1.02040816e+02,\n",
       "       5.22648084e+01])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_23 (Masking)            (None, 50)           0           input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 50, 50)       72900       masking_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           (None, 50, 14)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 50, 50)       0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "masking_24 (Masking)            (None, 50, 14)       0           input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 50, 64)       0           dropout_12[0][0]                 \n",
      "                                                                 masking_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 50, 200)      33000       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 50, 21)       4221        bidirectional_12[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 110,121\n",
      "Trainable params: 110,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/btech/cse/2016/mukuntha.cs16/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 648 samples, validate on 72 samples\n",
      "Epoch 1/3\n",
      "648/648 [==============================] - 31s 49ms/step - loss: 0.1598 - accuracy: 0.9369 - val_loss: 0.1139 - val_accuracy: 0.9510\n",
      "Epoch 2/3\n",
      "648/648 [==============================] - 28s 43ms/step - loss: 0.1105 - accuracy: 0.9436 - val_loss: 0.1094 - val_accuracy: 0.9510\n",
      "Epoch 3/3\n",
      "648/648 [==============================] - 30s 47ms/step - loss: 0.0975 - accuracy: 0.9446 - val_loss: 0.0999 - val_accuracy: 0.9489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/btech/cse/2016/mukuntha.cs16/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[still updating...] Accuracy: 0.9464985994397759, Precision: 0.14016565418865903, Recall: 0.0832463924150875, FScore: 0.09526316369655244\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_25 (Masking)            (None, 50)           0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 50, 50)       72900       masking_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           (None, 50, 14)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 50, 50)       0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "masking_26 (Masking)            (None, 50, 14)       0           input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 50, 64)       0           dropout_13[0][0]                 \n",
      "                                                                 masking_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 50, 200)      33000       concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 50, 21)       4221        bidirectional_13[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 110,121\n",
      "Trainable params: 110,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/btech/cse/2016/mukuntha.cs16/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 648 samples, validate on 72 samples\n",
      "Epoch 1/3\n",
      "648/648 [==============================] - 32s 50ms/step - loss: 0.1634 - accuracy: 0.9370 - val_loss: 0.1197 - val_accuracy: 0.9517\n",
      "Epoch 2/3\n",
      "648/648 [==============================] - 32s 50ms/step - loss: 0.1106 - accuracy: 0.9460 - val_loss: 0.1054 - val_accuracy: 0.9510\n",
      "Epoch 3/3\n",
      "648/648 [==============================] - 31s 47ms/step - loss: 0.0963 - accuracy: 0.9475 - val_loss: 0.1034 - val_accuracy: 0.9489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/btech/cse/2016/mukuntha.cs16/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[still updating...] Accuracy: 0.9403805496828752, Precision: 0.11589504151396689, Recall: 0.06899475490711411, FScore: 0.07873944423485597\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_27 (InputLayer)           (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_27 (Masking)            (None, 50)           0           input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 50, 50)       72900       masking_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_28 (InputLayer)           (None, 50, 14)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 50, 50)       0           embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "masking_28 (Masking)            (None, 50, 14)       0           input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 50, 64)       0           dropout_14[0][0]                 \n",
      "                                                                 masking_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 50, 200)      33000       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, 50, 21)       4221        bidirectional_14[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 110,121\n",
      "Trainable params: 110,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/btech/cse/2016/mukuntha.cs16/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 648 samples, validate on 72 samples\n",
      "Epoch 1/3\n",
      "648/648 [==============================] - 34s 52ms/step - loss: 0.1603 - accuracy: 0.9368 - val_loss: 0.1172 - val_accuracy: 0.9510\n",
      "Epoch 2/3\n",
      "648/648 [==============================] - 27s 41ms/step - loss: 0.1108 - accuracy: 0.9449 - val_loss: 0.1074 - val_accuracy: 0.9538\n",
      "Epoch 3/3\n",
      "648/648 [==============================] - 36s 56ms/step - loss: 0.0976 - accuracy: 0.9459 - val_loss: 0.1019 - val_accuracy: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/btech/cse/2016/mukuntha.cs16/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[still updating...] Accuracy: 0.9404218928164196, Precision: 0.12134912839542243, Recall: 0.06497529531785705, FScore: 0.0740852622516546\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_29 (Masking)            (None, 50)           0           input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 50, 50)       72900       masking_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           (None, 50, 14)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 50, 50)       0           embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "masking_30 (Masking)            (None, 50, 14)       0           input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 50, 64)       0           dropout_15[0][0]                 \n",
      "                                                                 masking_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 50, 200)      33000       concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistri (None, 50, 21)       4221        bidirectional_15[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 110,121\n",
      "Trainable params: 110,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/btech/cse/2016/mukuntha.cs16/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 648 samples, validate on 72 samples\n",
      "Epoch 1/3\n",
      "648/648 [==============================] - 31s 48ms/step - loss: 0.1650 - accuracy: 0.9330 - val_loss: 0.1208 - val_accuracy: 0.9517\n",
      "Epoch 2/3\n",
      "648/648 [==============================] - 34s 53ms/step - loss: 0.1156 - accuracy: 0.9413 - val_loss: 0.1039 - val_accuracy: 0.9510\n",
      "Epoch 3/3\n",
      "648/648 [==============================] - 33s 51ms/step - loss: 0.1010 - accuracy: 0.9422 - val_loss: 0.1001 - val_accuracy: 0.9510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/btech/cse/2016/mukuntha.cs16/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[still updating...] Accuracy: 0.9438114228742345, Precision: 0.11927609562113302, Recall: 0.06208732464361825, FScore: 0.0702476013560719\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_31 (InputLayer)           (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_31 (Masking)            (None, 50)           0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 50, 50)       72900       masking_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_32 (InputLayer)           (None, 50, 14)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 50, 50)       0           embedding_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "masking_32 (Masking)            (None, 50, 14)       0           input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 50, 64)       0           dropout_16[0][0]                 \n",
      "                                                                 masking_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 50, 200)      33000       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, 50, 21)       4221        bidirectional_16[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 110,121\n",
      "Trainable params: 110,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/btech/cse/2016/mukuntha.cs16/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 648 samples, validate on 72 samples\n",
      "Epoch 1/3\n",
      "648/648 [==============================] - 36s 55ms/step - loss: 0.1794 - accuracy: 0.9303 - val_loss: 0.0982 - val_accuracy: 0.9599\n",
      "Epoch 2/3\n",
      "648/648 [==============================] - 37s 58ms/step - loss: 0.1170 - accuracy: 0.9418 - val_loss: 0.0741 - val_accuracy: 0.9592\n",
      "Epoch 3/3\n",
      "648/648 [==============================] - 32s 49ms/step - loss: 0.1008 - accuracy: 0.9435 - val_loss: 0.0676 - val_accuracy: 0.9585\n",
      "[still updating...] Accuracy: 0.9434210526315789, Precision: 0.11161119102313831, Recall: 0.06264203472689935, FScore: 0.07010134619525694\n",
      "Accuracy: 0.9434210526315789, Precision: 0.11161119102313831, Recall: 0.06264203472689935, FScore: 0.07010134619525694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/btech/cse/2016/mukuntha.cs16/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Build the test and training sets of sentences.\n",
    "kf = KFold(n_splits = 5, shuffle = False)\n",
    "parsed_sentences = np.asarray(parsed_sentences)\n",
    "scores = []\n",
    "scores1 = []\n",
    "y_pred_idx = []\n",
    "y_pred_idx1 = []\n",
    "y_test_idx = []\n",
    "y_test_idx1 = []\n",
    "\n",
    "preds = []\n",
    "\n",
    "for train_index, test_index in kf.split(parsed_sentences):\n",
    "    train_data = parsed_sentences[train_index]\n",
    "    test_data = parsed_sentences[test_index]\n",
    "    X_train = [np.asarray([a[0][0] for a in train_data]), np.asarray([a[0][1] for a in train_data])]\n",
    "    Y_train = np.asarray([a[1] for a in train_data])\n",
    "    X_test = [np.asarray([a[0][0] for a in test_data]), np.asarray([a[0][1] for a in test_data])]\n",
    "    Y_test = np.asarray([a[1] for a in test_data])\n",
    "    model = create_model()\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, Y_train, epochs=3, validation_split=0.1, batch_size=4)\n",
    "\n",
    "    y_pred_padded = np.argmax(model.predict(X_test), axis=-1)\n",
    "    y_true_padded = np.argmax(Y_test, axis=-1)\n",
    "    \n",
    "    for i in range(X_test[0].shape[0]):\n",
    "        for j in range(X_test[0].shape[1]):\n",
    "            if X_test[0][i][j] == word2idx['PAD']:\n",
    "                continue\n",
    "            else:\n",
    "                pred = y_pred_padded[i][j]\n",
    "                true = y_true_padded[i][j]\n",
    "                y_pred_idx.append(pred)\n",
    "                y_test_idx.append(true)\n",
    "                scores.append(pred == true)\n",
    "\n",
    "    prec_, rec_, fscore_, _ = precision_recall_fscore_support(y_test_idx, y_pred_idx, average = 'macro')\n",
    "    print('[still updating...] Accuracy: {}, Precision: {}, Recall: {}, FScore: {}'.format(np.asarray(scores).mean(), prec_, rec_, fscore_))\n",
    "    \n",
    "prec, rec, fscore, _ = precision_recall_fscore_support(y_test_idx, y_pred_idx, average = 'macro')\n",
    "print('Accuracy: {}, Precision: {}, Recall: {}, FScore: {}'.format(np.asarray(scores).mean(), prec, rec, fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = [np.asarray([a[0] for a in parsed_test_sentences]), np.asarray([a[1] for a in parsed_test_sentences])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_full = model.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 50, 21)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_list = []\n",
    "for i, s in enumerate(test_sentences):\n",
    "    output = []\n",
    "    for j, w in enumerate(s[0]):\n",
    "        output.append(np.argmax(predictions_full[i][j]))\n",
    "    predictions_list.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 7, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 17, 15, 15, 15, 15, 17, 17, 17, 15, 15, 15, 15, 15, 15, 17, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 17, 15, 15, 17, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 17, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 7, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 17, 17, 15, 15, 15, 15, 15, 15, 7, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 17, 17, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 9, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 7, 17, 15, 15, 15, 15, 15, 15, 15, 15, 15, 7, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 17, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 17, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({15: 1881, 7: 5, 17: 15, 9: 1})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(sum(predictions_list, []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
