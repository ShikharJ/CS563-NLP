{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries for Decision Tree Classifier.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the dataset for training examples.\n",
    "train_examples = []\n",
    "\n",
    "with open('WikiCREM/WikiCREM_train.txt') as fp:\n",
    "    i = 0\n",
    "    example = {}\n",
    "\n",
    "    for line in fp:\n",
    "        i += 1\n",
    "\n",
    "        if i == 1:\n",
    "            example['tokens'] = line.split()\n",
    "        elif i == 2:\n",
    "            for j, token in enumerate(example['tokens']):\n",
    "                if token == '[MASK]':\n",
    "                    example['mask_idx'] = j\n",
    "        elif i == 3:\n",
    "            example['candidates'] = line.rstrip().split(',')\n",
    "        elif i == 4:\n",
    "            example['true_label'] = line.rstrip()\n",
    "        else:\n",
    "            if 'mask_idx' in example.keys():\n",
    "                train_examples.append(example)\n",
    "\n",
    "            example = {}\n",
    "            i = 0\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the dataset for testing examples.\n",
    "test_examples = []\n",
    "\n",
    "with open('WikiCREM/WikiCREM_dev.txt') as fp:\n",
    "    i = 0\n",
    "    example = {}\n",
    "\n",
    "    for line in fp:\n",
    "        i += 1\n",
    "\n",
    "        if i == 1:\n",
    "            example['tokens'] = line.split()\n",
    "        elif i == 2:\n",
    "            for j, token in enumerate(example['tokens']):\n",
    "                if token == '[MASK]':\n",
    "                    example['mask_idx'] = j\n",
    "        elif i == 3:\n",
    "            example['candidates'] = line.rstrip().split(',')\n",
    "        elif i == 4:\n",
    "            example['true_label'] = line.rstrip()\n",
    "        else:\n",
    "            if 'mask_idx' in example.keys():\n",
    "                test_examples.append(example)\n",
    "\n",
    "            example = {}\n",
    "            i = 0\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the minimum distance between two matching NPs.\n",
    "def generate_matching_distance_feature(example):\n",
    "    p = 0\n",
    "    n = 0\n",
    "\n",
    "    for candidate in example['candidates']:\n",
    "        distance = 9999\n",
    "\n",
    "        for i, token in enumerate(example['tokens']):\n",
    "            if token in candidate.split():\n",
    "                distance = min(distance, abs(i - example['mask_idx']))\n",
    "\n",
    "        if candidate == example['true_label']:\n",
    "            p = distance\n",
    "        else:\n",
    "            n = distance\n",
    "\n",
    "    return p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the minimum distance between two non-matching NPs.\n",
    "def generate_non_matching_distance_feature(example):\n",
    "    p = 0\n",
    "    n = 0\n",
    "\n",
    "    for candidate in example['candidates']:\n",
    "        distance = 9999\n",
    "\n",
    "        for i, token in enumerate(example['tokens']):\n",
    "            if token in candidate.split():\n",
    "                distance = min(distance, abs(i - example['mask_idx']))\n",
    "\n",
    "        if candidate == example['true_label']:\n",
    "            n = distance\n",
    "        else:\n",
    "            p = distance\n",
    "\n",
    "    return p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the minimum sentence distance between two matching NPs.\n",
    "def generate_matching_sentence_distance_feature(example):\n",
    "    p = 0\n",
    "    n = 0\n",
    "\n",
    "    for candidate in example['candidates']:\n",
    "        distance = 9999\n",
    "        idx = -1\n",
    "        sentence_distance = 0\n",
    "\n",
    "        for i, token in enumerate(example['tokens']):\n",
    "            if token in candidate.split():\n",
    "                if abs(i - example['mask_idx']) < distance:\n",
    "                    distance = abs(i - example['mask_idx'])\n",
    "                    idx = i\n",
    "\n",
    "        for i in range(min(idx, example['mask_idx']), max(idx, example['mask_idx'])):\n",
    "            if example['tokens'][i] == '.':\n",
    "                sentence_distance += 1\n",
    "\n",
    "        if candidate == example['true_label']:\n",
    "            p = sentence_distance\n",
    "        else:\n",
    "            n = sentence_distance\n",
    "\n",
    "    return p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the minimum sentence distance between two non-matching NPs.\n",
    "def generate_non_matching_sentence_distance_feature(example):\n",
    "    p = 0\n",
    "    n = 0\n",
    "\n",
    "    for candidate in example['candidates']:\n",
    "        distance = 9999\n",
    "        idx = -1\n",
    "        sentence_distance = 0\n",
    "\n",
    "        for i, token in enumerate(example['tokens']):\n",
    "            if token in candidate.split():\n",
    "                if abs(i - example['mask_idx']) < distance:\n",
    "                    distance = abs(i - example['mask_idx'])\n",
    "                    idx = i\n",
    "\n",
    "        for i in range(min(idx, example['mask_idx']), max(idx, example['mask_idx'])):\n",
    "            if example['tokens'][i] == '.':\n",
    "                sentence_distance += 1\n",
    "\n",
    "        if candidate == example['true_label']:\n",
    "            n = sentence_distance\n",
    "        else:\n",
    "            p = sentence_distance\n",
    "\n",
    "    return p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the repetition count of matching NPs.\n",
    "def generate_matching_repetition_count_feature(example):\n",
    "    p = 0\n",
    "    n = 0\n",
    "\n",
    "    for candidate in example['candidates']:\n",
    "        count = 0\n",
    "\n",
    "        for c in candidate.split():\n",
    "            count = max(example['tokens'].count(c), count)\n",
    "\n",
    "        if candidate == example['true_label']:\n",
    "            p = count\n",
    "        else:\n",
    "            n = count\n",
    "        \n",
    "    return p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the repetition count of non-matching NPs.\n",
    "def generate_non_matching_repetition_count_feature(example):\n",
    "    p = 0\n",
    "    n = 0\n",
    "\n",
    "    for candidate in example['candidates']:\n",
    "        count = 0\n",
    "\n",
    "        for c in candidate.split():\n",
    "            count = max(example['tokens'].count(c), count)\n",
    "\n",
    "        if candidate == example['true_label']:\n",
    "            n = count\n",
    "        else:\n",
    "            p = count\n",
    "        \n",
    "    return p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the existence of matching anaphoric NPs.\n",
    "def generate_matching_anaphor_feature(example):\n",
    "    p = 0\n",
    "    n = 0\n",
    "\n",
    "    for candidate in example['candidates']:\n",
    "        flag = 0\n",
    "\n",
    "        for i, token in enumerate(example['tokens']):\n",
    "            if token in candidate.split():\n",
    "                if i - example['mask_idx'] < 0:\n",
    "                    flag = 1\n",
    "\n",
    "        if candidate == example['true_label']:\n",
    "            p = flag\n",
    "        else:\n",
    "            n = flag\n",
    "\n",
    "    return p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the existence of non-matching anaphoric NPs.\n",
    "def generate_non_matching_anaphor_feature(example):\n",
    "    p = 0\n",
    "    n = 0\n",
    "\n",
    "    for candidate in example['candidates']:\n",
    "        flag = 0\n",
    "\n",
    "        for i, token in enumerate(example['tokens']):\n",
    "            if token in candidate.split():\n",
    "                if i - example['mask_idx'] < 0:\n",
    "                    flag = 1\n",
    "\n",
    "        if candidate == example['true_label']:\n",
    "            n = flag\n",
    "        else:\n",
    "            p = flag\n",
    "\n",
    "    return p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the existence of matching cataphoric NPs.\n",
    "def generate_matching_cataphor_feature(example):\n",
    "    p = 0\n",
    "    n = 0\n",
    "\n",
    "    for candidate in example['candidates']:\n",
    "        flag = 0\n",
    "\n",
    "        for i, token in enumerate(example['tokens']):\n",
    "            if token in candidate.split():\n",
    "                if i - example['mask_idx'] > 0:\n",
    "                    flag = 1\n",
    "\n",
    "        if candidate == example['true_label']:\n",
    "            p = flag\n",
    "        else:\n",
    "            n = flag\n",
    "\n",
    "    return p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the existence of non-matching cataphoric NPs.\n",
    "def generate_non_matching_cataphor_feature(example):\n",
    "    p = 0\n",
    "    n = 0\n",
    "\n",
    "    for candidate in example['candidates']:\n",
    "        flag = 0\n",
    "\n",
    "        for i, token in enumerate(example['tokens']):\n",
    "            if token in candidate.split():\n",
    "                if i - example['mask_idx'] > 0:\n",
    "                    flag = 1\n",
    "\n",
    "        if candidate == example['true_label']:\n",
    "            n = flag\n",
    "        else:\n",
    "            p = flag\n",
    "\n",
    "    return p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently we generate the following sets of features:\n",
    "# 1) Minimum Distance to Matching NP\n",
    "# 2) Minimum Distance to Non-Matching NP\n",
    "# 3) Minimum Sentence Distance to Matching NP\n",
    "# 4) Minimum Sentence Distance to Non-Matching NP\n",
    "# 5) Number of Matching Repetions Within The Passage\n",
    "# 6) Number of Non-Matching Repetions Within The Passage\n",
    "# 7) Presence of Matching Anaphor\n",
    "# 8) Presence of Non-Matching Anaphor\n",
    "# 9) Presence of Matching Cataphor\n",
    "# 9) Presence of Matching Cataphor\n",
    "def feature_set_generation(examples):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for example in examples:\n",
    "        p1, n1 = generate_matching_distance_feature(example)\n",
    "        p2, n2 = generate_non_matching_distance_feature(example)\n",
    "        p3, n3 = generate_matching_sentence_distance_feature(example)\n",
    "        p4, n4 = generate_non_matching_sentence_distance_feature(example)\n",
    "        p5, n5 = generate_matching_repetition_count_feature(example)\n",
    "        p6, n6 = generate_non_matching_repetition_count_feature(example)\n",
    "        p7, n7 = generate_matching_anaphor_feature(example)\n",
    "        p8, n8 = generate_non_matching_anaphor_feature(example)\n",
    "        p9, n9 = generate_matching_cataphor_feature(example)\n",
    "        p10, n10 = generate_non_matching_cataphor_feature(example)\n",
    "        X.append([p1, p2, p3, p4, p5, p6, p7, p8, p9, p10])\n",
    "        Y.append(1)\n",
    "        X.append([n1, n2, n3, n4, n5, n6, n7, n8, n9, n10])\n",
    "        Y.append(0)\n",
    "            \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classification and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train, Y_Train = feature_set_generation(train_examples)\n",
    "X_Test, Y_Test = feature_set_generation(test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold Cross Validation Score:  0.6800051005658361\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(DecisionTreeClassifier(criterion = 'entropy', random_state = 42), X_Train, Y_Train, cv = 10)\n",
    "\n",
    "sum_scores = 0\n",
    "for score in scores:\n",
    "    sum_scores += score\n",
    "sum_scores /= len(scores)\n",
    "\n",
    "print('10-Fold Cross Validation Score: ', sum_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion = 'entropy', random_state = 42).fit(X_Train, Y_Train)\n",
    "Y_Pred = clf.predict(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6836  Precision:  0.6836764387867655  Recall:  0.6836  F-Score:  0.6835670783188283\n"
     ]
    }
   ],
   "source": [
    "prec, rec, fscore, _ = precision_recall_fscore_support(Y_Test, Y_Pred, average = 'macro')\n",
    "print('Accuracy: ', accuracy_score(Y_Test, Y_Pred), ' Precision: ', prec, ' Recall: ', rec, ' F-Score: ', fscore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
