{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = []\n",
    "\n",
    "with open('WikiCREM/WikiCREM_train.txt') as fp:\n",
    "    i = 0\n",
    "    example = {}\n",
    "\n",
    "    for line in fp:\n",
    "        i += 1\n",
    "\n",
    "        if i == 1:\n",
    "            example['tokens'] = line.split()\n",
    "        elif i == 2:\n",
    "            for j, token in enumerate(example['tokens']):\n",
    "                if token == '[MASK]':\n",
    "                    example['mask_idx'] = j\n",
    "        elif i == 3:\n",
    "            example['candidates'] = line.rstrip().split(',')\n",
    "        elif i == 4:\n",
    "            example['true_label'] = line.rstrip()\n",
    "        else:\n",
    "            train_examples.append(example)\n",
    "            example = {}\n",
    "            i = 0\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = []\n",
    "\n",
    "with open('WikiCREM/WikiCREM_dev.txt') as fp:\n",
    "    i = 0\n",
    "    example = {}\n",
    "\n",
    "    for line in fp:\n",
    "        i += 1\n",
    "\n",
    "        if i == 1:\n",
    "            example['tokens'] = line.split()\n",
    "        elif i == 2:\n",
    "            for j, token in enumerate(example['tokens']):\n",
    "                if token == '[MASK]':\n",
    "                    example['mask_idx'] = j\n",
    "        elif i == 3:\n",
    "            example['candidates'] = line.rstrip().split(',')\n",
    "        elif i == 4:\n",
    "            example['true_label'] = line.rstrip()\n",
    "        else:\n",
    "            test_examples.append(example)\n",
    "            example = {}\n",
    "            i = 0\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matching_distance_feature(example):\n",
    "    p = 0\n",
    "    n = 0\n",
    "\n",
    "    for candidate in example['candidates']:\n",
    "        distance = 9999\n",
    "\n",
    "        for i, token in enumerate(example['tokens']):\n",
    "            if token in candidate.split():\n",
    "                distance = min(distance, abs(i - example['mask_idx']))\n",
    "\n",
    "        if candidate == example['true_label']:\n",
    "            p = distance\n",
    "        else:\n",
    "            n = distance\n",
    "\n",
    "    return p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_non_matching_distance_feature(example):\n",
    "    p = 0\n",
    "    n = 0\n",
    "\n",
    "    for candidate in example['candidates']:\n",
    "        distance = 9999\n",
    "\n",
    "        for i, token in enumerate(example['tokens']):\n",
    "            if token in candidate.split():\n",
    "                distance = min(distance, abs(i - example['mask_idx']))\n",
    "\n",
    "        if candidate == example['true_label']:\n",
    "            n = distance\n",
    "        else:\n",
    "            p = distance\n",
    "\n",
    "    return p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_distance_feature(example):\n",
    "    p = 0\n",
    "    n = 0\n",
    "\n",
    "    for candidate in example['candidates']:\n",
    "        distance = 9999\n",
    "        idx = -1\n",
    "        sentence_distance = 0\n",
    "\n",
    "        for i, token in enumerate(example['tokens']):\n",
    "            if token in candidate.split():\n",
    "                if abs(i - example['mask_idx']) < distance:\n",
    "                    distance = abs(i - example['mask_idx'])\n",
    "                    idx = i\n",
    "\n",
    "        for i in range(min(idx, example['mask_idx']), max(idx, example['mask_idx'])):\n",
    "            if example['tokens'][i] == '.':\n",
    "                sentence_distance += 1\n",
    "\n",
    "        if candidate == example['true_label']:\n",
    "            p = sentence_distance\n",
    "        else:\n",
    "            n = sentence_distance\n",
    "\n",
    "    return p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_repetition_count_feature(example):\n",
    "    p = 0\n",
    "    n = 0\n",
    "\n",
    "    for candidate in example['candidates']:\n",
    "        count = 0\n",
    "\n",
    "        for c in candidate.split():\n",
    "            count = max(example['tokens'].count(c), count)\n",
    "\n",
    "        if candidate == example['true_label']:\n",
    "            p = count\n",
    "        else:\n",
    "            n = count\n",
    "        \n",
    "    return p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_anaphor_feature(example):\n",
    "    p = 0\n",
    "    n = 0\n",
    "\n",
    "    for candidate in example['candidates']:\n",
    "        flag = 0\n",
    "\n",
    "        for i, token in enumerate(example['tokens']):\n",
    "            if token in candidate.split():\n",
    "                if i - example['mask_idx'] < 0:\n",
    "                    flag = 1\n",
    "\n",
    "        if candidate == example['true_label']:\n",
    "            p = flag\n",
    "        else:\n",
    "            n = flag\n",
    "\n",
    "    return p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cataphor_feature(example):\n",
    "    p = 0\n",
    "    n = 0\n",
    "\n",
    "    for candidate in example['candidates']:\n",
    "        flag = 0\n",
    "\n",
    "        for i, token in enumerate(example['tokens']):\n",
    "            if token in candidate.split():\n",
    "                if i - example['mask_idx'] > 0:\n",
    "                    flag = 1\n",
    "\n",
    "        if candidate == example['true_label']:\n",
    "            p = flag\n",
    "        else:\n",
    "            n = flag\n",
    "\n",
    "    return p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently we generate the following sets of features:\n",
    "# 1) Minimum Distance to Matching NP\n",
    "# 2) Minimum Distance to Non-Matching NP\n",
    "# 3) Minimum Sentence Distance to Matching NP\n",
    "# 4) Number of Repitions Within The Passage\n",
    "# 5) Presence of Anaphor\n",
    "# 6) Presence of Cataphor\n",
    "def feature_set_generation(examples):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for example in examples:\n",
    "        p1, n1 = generate_matching_distance_feature(example)\n",
    "        p2, n2 = generate_non_matching_distance_feature(example)\n",
    "        p3, n3 = generate_sentence_distance_feature(example)\n",
    "        p4, n4 = generate_repetition_count_feature(example)\n",
    "        p5, n5 = generate_anaphor_feature(example)\n",
    "        p6, n6 = generate_cataphor_feature(example)\n",
    "        X.append([p1, p2, p3, p4, p5, p6])\n",
    "        Y.append([1])\n",
    "        X.append([n1, n2, n3, n4, n5, n6])\n",
    "        Y.append([0])\n",
    "            \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train, Y_Train = feature_set_generation(train_examples)\n",
    "X_Test, Y_Test = feature_set_generation(test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14, 4, 1, 1, 1, 0], [4, 14, 0, 2, 1, 1]]\n",
      "[[1], [0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_Test)\n",
    "print(Y_Test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
